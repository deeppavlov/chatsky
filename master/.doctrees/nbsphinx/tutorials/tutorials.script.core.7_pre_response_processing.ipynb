{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35ef328",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Core: 7. Pre-response processing\n",
    "\n",
    "Here, [PRE_RESPONSE](../apiref/chatsky.core.script.rst#chatsky.core.script.PRE_RESPONSE)\n",
    "is demonstrated which can be used for\n",
    "additional context processing before response handlers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fcedd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:55.866387Z",
     "iopub.status.busy": "2025-02-18T10:21:55.865971Z",
     "iopub.status.idle": "2025-02-18T10:21:57.037734Z",
     "shell.execute_reply": "2025-02-18T10:21:57.037006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "%pip install -q chatsky==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34f1231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:57.040086Z",
     "iopub.status.busy": "2025-02-18T10:21:57.039860Z",
     "iopub.status.idle": "2025-02-18T10:21:58.666468Z",
     "shell.execute_reply": "2025-02-18T10:21:58.665839Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from chatsky import (\n",
    "    GLOBAL,\n",
    "    LOCAL,\n",
    "    RESPONSE,\n",
    "    TRANSITIONS,\n",
    "    PRE_RESPONSE,\n",
    "    Context,\n",
    "    Message,\n",
    "    MessageInitTypes,\n",
    "    BaseResponse,\n",
    "    Transition as Tr,\n",
    "    Pipeline,\n",
    "    destinations as dst,\n",
    "    processing as proc,\n",
    ")\n",
    "\n",
    "from chatsky.utils.testing.common import (\n",
    "    check_happy_path,\n",
    "    is_interactive_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661b8cf",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "Processing functions have the same signature as\n",
    "conditions, responses or destinations\n",
    "except they don't return anything:\n",
    "\n",
    ".. python:\n",
    "\n",
    "    class MyProcessing(BaseProcessing):\n",
    "        async def call(self, ctx: Context) -> None:\n",
    "            ...\n",
    "\n",
    "\n",
    "The main way for processing functions to interact with the script\n",
    "is modifying `ctx.current_node`, which is used by pipeline\n",
    "to store a copy of the current node in script.\n",
    "Any of its attributes can be safely edited, and these changes will\n",
    "only have an effect during the current turn of the current context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424ddda",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "In this tutorial we'll subclass\n",
    "[ModifyResponse](../apiref/chatsky.processing.standard.rst#chatsky.processing.standard.ModifyResponse)\n",
    "processing function so that it would modify response\n",
    "of the current node to include a prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686198fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:58.669465Z",
     "iopub.status.busy": "2025-02-18T10:21:58.668882Z",
     "iopub.status.idle": "2025-02-18T10:21:58.674392Z",
     "shell.execute_reply": "2025-02-18T10:21:58.673801Z"
    }
   },
   "outputs": [],
   "source": [
    "class AddPrefix(proc.ModifyResponse):\n",
    "    prefix: str\n",
    "\n",
    "    def __init__(self, prefix: str):\n",
    "        # basemodel does not allow positional arguments by default\n",
    "        super().__init__(prefix=prefix)\n",
    "\n",
    "    async def modified_response(\n",
    "        self, original_response: BaseResponse, ctx: Context\n",
    "    ) -> MessageInitTypes:\n",
    "        result = await original_response(ctx)\n",
    "\n",
    "        if result.text is not None:\n",
    "            result.text = f\"{self.prefix}: {result.text}\"\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d801db",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "\n",
    "You can use `ModifyResponse` to catch exceptions in response functions:\n",
    "\n",
    ".. python:\n",
    "\n",
    "    class ExceptionHandler(proc.ModifyResponse):\n",
    "        async def modified_response(self, original_response, ctx):\n",
    "            try:\n",
    "                return await original_response(ctx)\n",
    "            except Exception as exc:\n",
    "                return str(exc)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32580ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:58.676698Z",
     "iopub.status.busy": "2025-02-18T10:21:58.676283Z",
     "iopub.status.idle": "2025-02-18T10:21:58.682349Z",
     "shell.execute_reply": "2025-02-18T10:21:58.681744Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "toy_script = {\n",
    "    \"root\": {\n",
    "        \"start\": {\n",
    "            TRANSITIONS: [Tr(dst=(\"flow\", \"step_0\"))],\n",
    "        },\n",
    "        \"fallback\": {RESPONSE: \"the end\"},\n",
    "    },\n",
    "    GLOBAL: {\n",
    "        PRE_RESPONSE: {\n",
    "            \"proc_name_1\": AddPrefix(\"l1_global\"),\n",
    "            \"proc_name_2\": AddPrefix(\"l2_global\"),\n",
    "        }\n",
    "    },\n",
    "    \"flow\": {\n",
    "        LOCAL: {\n",
    "            PRE_RESPONSE: {\n",
    "                \"proc_name_2\": AddPrefix(\"l2_local\"),\n",
    "                \"proc_name_3\": AddPrefix(\"l3_local\"),\n",
    "            },\n",
    "            TRANSITIONS: [Tr(dst=dst.Forward(loop=True))],\n",
    "        },\n",
    "        \"step_0\": {\n",
    "            RESPONSE: \"first\",\n",
    "        },\n",
    "        \"step_1\": {\n",
    "            PRE_RESPONSE: {\"proc_name_1\": AddPrefix(\"l1_step_1\")},\n",
    "            RESPONSE: \"second\",\n",
    "        },\n",
    "        \"step_2\": {\n",
    "            PRE_RESPONSE: {\"proc_name_2\": AddPrefix(\"l2_step_2\")},\n",
    "            RESPONSE: \"third\",\n",
    "        },\n",
    "        \"step_3\": {\n",
    "            PRE_RESPONSE: {\"proc_name_3\": AddPrefix(\"l3_step_3\")},\n",
    "            RESPONSE: \"fourth\",\n",
    "        },\n",
    "        \"step_4\": {\n",
    "            PRE_RESPONSE: {\"proc_name_4\": AddPrefix(\"l4_step_4\")},\n",
    "            RESPONSE: \"fifth\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804423ea",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "The order of execution for processing functions is as follows:\n",
    "\n",
    "1. All node-specific functions are executed in the order of definition;\n",
    "2. All local functions are executed in the order of definition except those with\n",
    "   keys matching to previously executed functions;\n",
    "3. All global functions are executed in the order of definition\n",
    "   except those with keys matching to previously executed functions.\n",
    "\n",
    "That means that if both global and local nodes\n",
    "define a processing function with key \"processing_name\",\n",
    "only the one inside the local node will be executed.\n",
    "\n",
    "This demonstrated in the happy path below\n",
    "(the first prefix in the text is the last one to execute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1f104d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:58.684647Z",
     "iopub.status.busy": "2025-02-18T10:21:58.684219Z",
     "iopub.status.idle": "2025-02-18T10:21:58.688070Z",
     "shell.execute_reply": "2025-02-18T10:21:58.687398Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "happy_path = (\n",
    "    (Message(), \"l1_global: l3_local: l2_local: first\"),\n",
    "    (Message(), \"l3_local: l2_local: l1_step_1: second\"),\n",
    "    (Message(), \"l1_global: l3_local: l2_step_2: third\"),\n",
    "    (Message(), \"l1_global: l2_local: l3_step_3: fourth\"),\n",
    "    (Message(), \"l1_global: l3_local: l2_local: l4_step_4: fifth\"),\n",
    "    (Message(), \"l1_global: l3_local: l2_local: first\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723ec20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T10:21:58.690226Z",
     "iopub.status.busy": "2025-02-18T10:21:58.689781Z",
     "iopub.status.idle": "2025-02-18T10:21:58.725333Z",
     "shell.execute_reply": "2025-02-18T10:21:58.724642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: \n",
      "BOT : text='l1_global: l3_local: l2_local: first'\n",
      "USER: \n",
      "BOT : text='l3_local: l2_local: l1_step_1: second'\n",
      "USER: \n",
      "BOT : text='l1_global: l3_local: l2_step_2: third'\n",
      "USER: \n",
      "BOT : text='l1_global: l2_local: l3_step_3: fourth'\n",
      "USER: \n",
      "BOT : text='l1_global: l3_local: l2_local: l4_step_4: fifth'\n",
      "USER: \n",
      "BOT : text='l1_global: l3_local: l2_local: first'\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    script=toy_script,\n",
    "    start_label=(\"root\", \"start\"),\n",
    "    fallback_label=(\"root\", \"fallback\"),\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_happy_path(pipeline, happy_path, printout=True)\n",
    "    if is_interactive_mode():\n",
    "        pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
