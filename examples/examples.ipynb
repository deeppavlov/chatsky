{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc511bb",
   "metadata": {},
   "source": [
    "**_Note:_** examples here use the python interface of the parser but it's identical to parser's cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f46885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import df_script_parser\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9831000",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dir = Path(mkdtemp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98ac5e",
   "metadata": {},
   "source": [
    "## 1. Basic examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a53e48",
   "metadata": {},
   "source": [
    "This basic example shows that parser can extract import, dictionaries, function calls as well as project requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a5768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = example_dir / \"basic_example\"\n",
    "working_dir.mkdir()\n",
    "main_file = working_dir / \"main.py\"\n",
    "main_file.touch()\n",
    "yaml_file = working_dir / \"script.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c04456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements:\n",
      "- df-engine==0.9.0\n",
      "- git+https://github.com/navdeep-G/setup.py.git@3a03ee20c0d2b795c8d5cb1aa1d7c3c6468d2ffc\n",
      "namespaces:\n",
      "  main:\n",
      "    Path: !from pathlib Path\n",
      "    dfe: !import df_engine\n",
      "    mypackage: !import mypackage\n",
      "    dictionary:\n",
      "      '1': Path\n",
      "      '2': dfe\n",
      "      '3':\n",
      "        '4': mypackage\n",
      "      '4': text\n",
      "    result: !call\n",
      "      name: this_function_does_not_exist\n",
      "      args:\n",
      "        0: dictionary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(main_file, \"w\") as main:\n",
    "    main.write(\"\"\"\n",
    "from pathlib import Path\n",
    "import df_engine as dfe\n",
    "import mypackage\n",
    "\n",
    "dictionary = {\n",
    "    1: Path,\n",
    "    2: dfe,\n",
    "    3: {4: mypackage},\n",
    "    4: \"text\",\n",
    "}\n",
    "\n",
    "result = this_function_does_not_exist(dictionary)\n",
    "    \"\"\")\n",
    "\n",
    "df_script_parser.py2yaml(\n",
    "    root_file=main_file,\n",
    "    project_root_dir=working_dir,\n",
    "    output_file=yaml_file\n",
    ")\n",
    "\n",
    "with open(yaml_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a677fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:File /tmp/tmpntos4xps/basic_example/main.py already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pathlib import Path as Path\n",
      "import df_engine as dfe\n",
      "import mypackage as mypackage\n",
      "\n",
      "dictionary = {1: Path, 2: dfe, 3: {4: mypackage}, 4: \"text\"}\n",
      "result = this_function_does_not_exist(dictionary)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_script_parser.yaml2py(\n",
    "    yaml_file=yaml_file,\n",
    "    extract_to_directory=working_dir\n",
    ")\n",
    "\n",
    "with open(main_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc74b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df-engine==0.9.0\n",
      "git+https://github.com/navdeep-G/setup.py.git@3a03ee20c0d2b795c8d5cb1aa1d7c3c6468d2ffc\n"
     ]
    }
   ],
   "source": [
    "with open(working_dir / \"requirements.txt\", \"r\") as reqs:\n",
    "    print(reqs.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d86ab0",
   "metadata": {},
   "source": [
    "**_Note:_** if you want to override those requirements use the ``requirements`` flag of ``df_script_parser.py2yaml``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b94fea",
   "metadata": {},
   "source": [
    "## 2. Str tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d665ff",
   "metadata": {},
   "source": [
    "As you can see in a previous example both dictionary values ``Path`` and ``text`` are written in plain text. How did ``yaml2py`` parser figure out that it needs to put quotations around ``text``? Parser checks every plain text on whether it could be a correct line of python code. If it isn't parser knows that it's a string.\n",
    "\n",
    "But what if you want to use a string that is also a correct line of python code? That's where ``!str`` tag comes in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36189f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = example_dir / \"str_tag\"\n",
    "working_dir.mkdir()\n",
    "main_file = working_dir / \"main.py\"\n",
    "main_file.touch()\n",
    "yaml_file = working_dir / \"script.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ae141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Value printd is not a correct line of python code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements: []\n",
      "namespaces:\n",
      "  main:\n",
      "    Path: !from pathlib Path\n",
      "    dictionary:\n",
      "      '1': Path\n",
      "      '2': !str Path\n",
      "      '3': print\n",
      "      '4': !str print\n",
      "      '5': !py printd\n",
      "      '6': printd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(main_file, \"w\") as main:\n",
    "    main.write(\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "dictionary = {\n",
    "    1: Path,\n",
    "    2: \"Path\",\n",
    "    3: print,\n",
    "    4: \"print\",\n",
    "    5: printd,\n",
    "    6: \"printd\"\n",
    "}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "df_script_parser.py2yaml(\n",
    "    root_file=main_file,\n",
    "    project_root_dir=working_dir,\n",
    "    output_file=yaml_file\n",
    ")\n",
    "\n",
    "with open(yaml_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62c2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:File /tmp/tmpntos4xps/str_tag/main.py already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pathlib import Path as Path\n",
      "\n",
      "dictionary = {1: Path, 2: \"Path\", 3: print, 4: \"print\", 5: printd, 6: \"printd\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_script_parser.yaml2py(\n",
    "    yaml_file=yaml_file,\n",
    "    extract_to_directory=working_dir\n",
    ")\n",
    "\n",
    "with open(main_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9d57f",
   "metadata": {},
   "source": [
    "if you want to specify if the parser should treat a value as a string or as a python line of code you could use tags ``!str`` or ``!py`` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc88e64",
   "metadata": {},
   "source": [
    "## 3. Recursive parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5f05f",
   "metadata": {},
   "source": [
    "If your projects contains several modules that are imported in your ``root_file`` they will be parsed as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2f14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = example_dir / \"recursive_parsing\"\n",
    "working_dir.mkdir()\n",
    "python_files = working_dir / \"python_files\"\n",
    "python_files.mkdir()\n",
    "main_file = python_files / \"main.py\"\n",
    "main_file.touch()\n",
    "\n",
    "some_package = python_files / \"some_package\"\n",
    "some_package.mkdir()\n",
    "(some_package / \"__init__.py\").touch()\n",
    "another_file = some_package / \"another_file.py\"\n",
    "another_file.touch()\n",
    "unparsed = python_files / \"unparsed.py\"\n",
    "unparsed.touch()\n",
    "yaml_file = working_dir / \"script.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a91eec4",
   "metadata": {},
   "source": [
    "The project has the following structure:\n",
    "\n",
    "``\n",
    "+-- python_files\n",
    "+--++-- main.py\n",
    "+--++-- some_package\n",
    "+--++--++-- another_file.py\n",
    "+--++-- unparsed.py\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d2325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Object another_file not found in some_package\n",
      "WARNING:root:File /tmp/tmpntos4xps/recursive_parsing/python_files/unparsed.py not included: File must contain only imports, dict declarations and function calls.\n",
      "            The first line of other type found: print(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements: []\n",
      "namespaces:\n",
      "  main:\n",
      "    another_file: !from some_package another_file\n",
      "    something: !from some_package.another_file something\n",
      "    something_else: !from some_package.another_file something_else\n",
      "    unparsed: !import unparsed\n",
      "    dictionary:\n",
      "      '1': something\n",
      "      '2': something_else\n",
      "      '3': unparsed.path\n",
      "  some_package.__init__: {}\n",
      "  some_package.another_file:\n",
      "    something: !import abc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(main_file, \"w\") as main:\n",
    "    main.write(\"\"\"\n",
    "from some_package import another_file\n",
    "from some_package.another_file import something, something_else\n",
    "import unparsed\n",
    "\n",
    "dictionary = {\n",
    "    1: something,\n",
    "    2: something_else,\n",
    "    3: unparsed.path\n",
    "}\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "with open(another_file, \"w\") as file:\n",
    "    file.write(\"\"\"\n",
    "import abc as something\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "with open(unparsed, \"w\") as file:\n",
    "    file.write(\"\"\"\n",
    "from pathlib import Path as path\n",
    "\n",
    "print(path)\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "df_script_parser.py2yaml(\n",
    "    root_file=main_file,\n",
    "    project_root_dir=python_files,\n",
    "    output_file=yaml_file\n",
    ")\n",
    "\n",
    "with open(yaml_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee664f6",
   "metadata": {},
   "source": [
    "As you can see ``unparsed.py`` wasn't parsed as it doesn't follow the parser structure rules described in [README.md](../README.md). Replacing ``print(path)`` with ``some_variable = print(path)`` will fix that issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716bec8",
   "metadata": {},
   "source": [
    "**_Note:_** If ``project_root_dir`` contains ``__init__.py`` file ``yaml2py`` parser will put all the files inside a new directory with the same name as ``project_root_dir`` inside ``extract_to_directory``. So the result will be:\n",
    "\n",
    "``\n",
    "+-- extract_to_directory\n",
    "+--++-- project_root_dir\n",
    "+--++--++-- __init__.py\n",
    "+--++--++-- ...\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495f870",
   "metadata": {},
   "source": [
    "## 4. Actor arg checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e9166",
   "metadata": {},
   "source": [
    "If your script contains a call to ``df_engine.core.Actor`` or ``df_engine.core.actor.Actor`` the arguments of that call will be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4927e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = example_dir / \"act_arg\"\n",
    "working_dir.mkdir()\n",
    "main_file = working_dir / \"main.py\"\n",
    "main_file.touch()\n",
    "yaml_file = working_dir / \"script.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130dd6be",
   "metadata": {},
   "source": [
    "So this works fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43bd2f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements:\n",
      "- df-engine==0.9.0\n",
      "namespaces:\n",
      "  main:\n",
      "    act: !from df_engine.core Actor\n",
      "    kw: !import df_engine.core.keywords\n",
      "    actor: !call\n",
      "      name: act\n",
      "      args:\n",
      "        script:\n",
      "          flow:\n",
      "            node:\n",
      "              kw.RESPONSE: hey\n",
      "        start_label:\n",
      "        - flow\n",
      "        - node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(main_file, \"w\") as main:\n",
    "    main.write(\"\"\"\n",
    "from df_engine.core import Actor as act\n",
    "import df_engine.core.keywords as kw\n",
    "\n",
    "actor = act(\n",
    "    {\"flow\": {\"node\": {kw.RESPONSE: \"hey\"}}},\n",
    "    (\"flow\", \"node\")\n",
    ")\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "df_script_parser.py2yaml(\n",
    "    root_file=main_file,\n",
    "    project_root_dir=working_dir,\n",
    "    output_file=yaml_file\n",
    ")\n",
    "\n",
    "with open(yaml_file, \"r\") as out:\n",
    "    print(out.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4644e3",
   "metadata": {},
   "source": [
    "While this fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af870223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'df_script_parser.utils.exceptions.ScriptValidationError'> Node keys should be keywords: ['flow', 'node', kw.response]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(main_file, \"w\") as main:\n",
    "        main.write(\"\"\"\n",
    "from df_engine.core import Actor as act\n",
    "import df_engine.core.keywords as kw\n",
    "\n",
    "script = {\"flow\": {\"node\": {kw.response: \"hey\"}}}\n",
    "\n",
    "actor = act(\n",
    "    start_label=(\"flow\", \"node\"),\n",
    "    script=script\n",
    ")\n",
    "\n",
    "        \"\"\")\n",
    "\n",
    "    df_script_parser.py2yaml(\n",
    "        root_file=main_file,\n",
    "        project_root_dir=working_dir,\n",
    "        output_file=yaml_file\n",
    "    )\n",
    "\n",
    "    with open(yaml_file, \"r\") as out:\n",
    "        print(out.read())\n",
    "except Exception as error:\n",
    "    print(type(error), error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8794ee4",
   "metadata": {},
   "source": [
    "**_Note:_** Actor argument checking works with recursive parsing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
