{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dea35f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# LLM: 4. Structured Output\n",
    "\n",
    "Chatsky provides two powerful ways to get structured output from LLMs:\n",
    "\n",
    "1. **Using BaseModel**: To get structured text content (like JSON).\n",
    "2. **Using Message subclass**: To add metadata to messages.\n",
    "\n",
    "This tutorial demonstrates both approaches with practical examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c102ef3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T09:21:27.159274Z",
     "iopub.status.busy": "2025-02-18T09:21:27.158585Z",
     "iopub.status.idle": "2025-02-18T09:21:28.504198Z",
     "shell.execute_reply": "2025-02-18T09:21:28.503368Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "%pip install -q chatsky[llm]==0.10.0 langchain-openai==0.2.8 langchain-anthropic==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33563a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T09:21:28.506995Z",
     "iopub.status.busy": "2025-02-18T09:21:28.506475Z",
     "iopub.status.idle": "2025-02-18T09:21:31.334083Z",
     "shell.execute_reply": "2025-02-18T09:21:31.333427Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from chatsky import (\n",
    "    TRANSITIONS,\n",
    "    RESPONSE,\n",
    "    GLOBAL,\n",
    "    Pipeline,\n",
    "    Transition as Tr,\n",
    "    conditions as cnd,\n",
    ")\n",
    "from chatsky.core.message import Message\n",
    "from chatsky.utils.testing import is_interactive_mode\n",
    "from chatsky.llm import LLM_API\n",
    "from chatsky.responses.llm import LLMResponse\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Load API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# Initialize our models\n",
    "movie_model = LLM_API(\n",
    "    ChatAnthropic(\n",
    "        model=\"claude-3.5-sonnet\", api_key=anthropic_api_key, temperature=0\n",
    "    ),\n",
    ")\n",
    "review_model = LLM_API(\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key, temperature=0),\n",
    ")\n",
    "\n",
    "\n",
    "# Define structured output schemas\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"Schema for movie details.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the movie\")\n",
    "    genre: str = Field(description=\"Genre of the movie\")\n",
    "    plot: str = Field(description=\"Plot of the movie in chapters\")\n",
    "    cast: list = Field(description=\"List of the actors\")\n",
    "\n",
    "\n",
    "class MovieReview(Message):\n",
    "    \"\"\"Schema for movie reviews (uses `Message.misc` for metadata).\"\"\"\n",
    "\n",
    "    text: str = Field(description=\"The actual review text\")\n",
    "    misc: dict = Field(\n",
    "        description=\"A dictionary with the following keys and values: \"\n",
    "        \"k: rating v [int]: number between 0 and 5, \"\n",
    "        \"k: spoiler_alert v [boolean]: is there a spoiler in this review\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f48a096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T09:21:31.337031Z",
     "iopub.status.busy": "2025-02-18T09:21:31.336353Z",
     "iopub.status.idle": "2025-02-18T09:21:31.344382Z",
     "shell.execute_reply": "2025-02-18T09:21:31.343593Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "script = {\n",
    "    GLOBAL: {\n",
    "        TRANSITIONS: [\n",
    "            Tr(\n",
    "                dst=(\"greeting_flow\", \"start_node\"),\n",
    "                cnd=cnd.ExactMatch(\"/start\"),\n",
    "            ),\n",
    "            Tr(dst=(\"movie_flow\", \"create\"), cnd=cnd.ExactMatch(\"/create\")),\n",
    "            Tr(dst=(\"movie_flow\", \"review\"), cnd=cnd.Regexp(\"/review .*\")),\n",
    "        ]\n",
    "    },\n",
    "    \"greeting_flow\": {\n",
    "        \"start_node\": {\n",
    "            RESPONSE: Message(\n",
    "                \"Welcome to MovieBot! Try:\\n\"\n",
    "                \"/create - Create a movie idea\\n\"\n",
    "                \"/review - Write a movie review\"\n",
    "            ),\n",
    "        },\n",
    "        \"fallback_node\": {\n",
    "            RESPONSE: Message(\"I didn't understand. Try /create or /review\"),\n",
    "            TRANSITIONS: [Tr(dst=\"start_node\")],\n",
    "        },\n",
    "    },\n",
    "    \"movie_flow\": {\n",
    "        \"create\": {\n",
    "            RESPONSE: LLMResponse(\n",
    "                llm_model_name=\"movie_model\",\n",
    "                prompt=\"Create a movie idea for the user.\",\n",
    "                message_schema=Movie,\n",
    "            ),\n",
    "            TRANSITIONS: [Tr(dst=(\"greeting_flow\", \"start_node\"))],\n",
    "        },\n",
    "        \"review\": {\n",
    "            RESPONSE: LLMResponse(\n",
    "                llm_model_name=\"review_model\",\n",
    "                prompt=\"Generate a movie review based on user's input. \"\n",
    "                \"Include rating, and mark if it contains spoilers. \"\n",
    "                \"Use JSON with the `text` and `misc` fields \"\n",
    "                \"to produce the output.\",\n",
    "                message_schema=MovieReview,\n",
    "            ),\n",
    "            TRANSITIONS: [Tr(dst=(\"greeting_flow\", \"start_node\"))],\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8aa74b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T09:21:31.346953Z",
     "iopub.status.busy": "2025-02-18T09:21:31.346693Z",
     "iopub.status.idle": "2025-02-18T09:21:31.351771Z",
     "shell.execute_reply": "2025-02-18T09:21:31.351163Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    script=script,\n",
    "    start_label=(\"greeting_flow\", \"start_node\"),\n",
    "    fallback_label=(\"greeting_flow\", \"fallback_node\"),\n",
    "    models={\"movie_model\": movie_model, \"review_model\": review_model},\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if is_interactive_mode():\n",
    "        pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
